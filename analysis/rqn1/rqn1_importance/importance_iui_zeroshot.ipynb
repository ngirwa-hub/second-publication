{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c074e5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   base_model  unique_iterations\n",
      "0  gemma3-12b                 50\n",
      "1   llama-pro                 50\n",
      "2     mistral                 50\n",
      "3        phi4                 50\n",
      "   base_model missing_iterations\n",
      "0  gemma3-12b                 []\n",
      "1   llama-pro                 []\n",
      "2     mistral                 []\n",
      "3        phi4                 []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('importance-cleaned.csv')\n",
    "\n",
    "\n",
    "df['iteration'] = pd.to_numeric(df['iteration'], errors='coerce')\n",
    "\n",
    "# unique iteration count per base model\n",
    "iters_per_base = (\n",
    "    df.groupby('base_model')['iteration']\n",
    "      .nunique(dropna=True)\n",
    "      .reset_index(name='unique_iterations')\n",
    "      .sort_values('base_model')\n",
    ")\n",
    "print(iters_per_base)\n",
    "\n",
    "# OPTIONAL: list missing iterations (should be empty lists if all 0..49 present)\n",
    "all_iters = set(range(50))\n",
    "missing_by_base = (\n",
    "    df.dropna(subset=['iteration'])\n",
    "      .groupby('base_model')['iteration']\n",
    "      .apply(lambda s: sorted(all_iters - set(s.astype(int).unique())))\n",
    "      .reset_index(name='missing_iterations')\n",
    "      .sort_values('base_model')\n",
    ")\n",
    "print(missing_by_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e9448ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 162 entries, 0 to 161\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   response_id     162 non-null    object\n",
      " 1   respondent_id   162 non-null    object\n",
      " 2   condition       162 non-null    object\n",
      " 3   variant_id      162 non-null    object\n",
      " 4   technology      162 non-null    object\n",
      " 5   rating_numeric  162 non-null    int64 \n",
      " 6   rating_text     162 non-null    object\n",
      " 7   justification   0 non-null      object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 11.4+ KB\n"
     ]
    }
   ],
   "source": [
    "#check human data\n",
    "df=pd.read_excel(\"importance-human.xlsx\")\n",
    "\n",
    "#filter only human data\n",
    "df_new=df[df['condition'] == 'human']\n",
    "\n",
    "#save to csv\n",
    "df_new.to_csv(\"importance-humanOnly.csv\", index=False)\n",
    "\n",
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32440c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "LLM_IN  = \"importance-cleaned.csv\"\n",
    "HUM_IN  = \"importance-humanOnly.csv\"\n",
    "OUT_FILE = \"merged_importance_zeroshot.csv\"\n",
    "\n",
    "# load\n",
    "llm = pd.read_csv(LLM_IN)\n",
    "hum = pd.read_csv(HUM_IN)\n",
    "\n",
    "# set source\n",
    "llm['source'] = 'llm'\n",
    "hum['source'] = 'human'\n",
    "\n",
    "# add condition\n",
    "llm['condition'] = 'ZEROSHOT'\n",
    "hum['condition'] = 'ZEROSHOT'\n",
    "\n",
    "# keep exactly these shared columns (in this order)\n",
    "cols = [\n",
    "    'row_id','source', 'condition', 'base_model','variant_id','model', 'dc_solution',\n",
    "    'rating','label','iteration','timestamp'\n",
    "]\n",
    "\n",
    "# some columns may be missing in human (base_model/variant_id/model/iteration/timestamp) â†’ create if needed\n",
    "for c in cols:\n",
    "    if c not in llm.columns: llm[c] = pd.NA\n",
    "    if c not in hum.columns: hum[c] = pd.NA\n",
    "\n",
    "merged = pd.concat([hum[cols], llm[cols]], ignore_index=True)\n",
    "\n",
    "\n",
    "merged.to_csv(OUT_FILE, index=False)\n",
    "print(\"Saved:\", OUT_FILE, \"rows:\", len(merged))\n",
    "print(\"Merged DataFrame info:\")\n",
    "print(merged.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92a42401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13362 entries, 0 to 13361\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   row_id       13362 non-null  object \n",
      " 1   source       13362 non-null  object \n",
      " 2   condition    13362 non-null  object \n",
      " 3   base_model   13200 non-null  object \n",
      " 4   variant_id   13362 non-null  object \n",
      " 5   model        13362 non-null  object \n",
      " 6   dc_solution  13362 non-null  object \n",
      " 7   rating       13362 non-null  int64  \n",
      " 8   label        13362 non-null  object \n",
      " 9   iteration    13200 non-null  float64\n",
      " 10  timestamp    13200 non-null  object \n",
      "dtypes: float64(1), int64(1), object(9)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"merged_importance_zeroshot.csv\")\n",
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
